{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6928d21-163c-4761-acce-0bd133e8416c",
   "metadata": {},
   "source": [
    "# Classic IR using sparse document vectors\n",
    "\n",
    "This notebook uses the `pyserini` Python package to explore classic IR methods using sparse embeddings and the BM25 algorithm. It is based on:\n",
    "* https://github.com/castorini/pyserini/blob/master/docs/usage-search.md\n",
    "* https://colab.research.google.com/github/castorini/anserini-notebooks/blob/master/pyserini_msmarco_passage_demo.ipynb#scrollTo=YacoQ28AZtQx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30400791-a8a2-433e-9a51-1a460a934ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set needed Java environment variables\n",
    "import os\n",
    "\n",
    "os.environ['JVM_PATH'] = '/ix/cs2731_2025f/class_env/lib/jvm/lib/server/libjvm.so'\n",
    "os.environ['JVM_PATH']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfc1cb9-6f4d-4ef4-91a8-16e8fab61ebb",
   "metadata": {},
   "source": [
    "# Build and query an IR system\n",
    "Includes:\n",
    "1. Load the preprocessed dataset (MS MARCO). Here's what the textbook says about MS Marco:\n",
    "\n",
    "> The MS MARCO (Microsoft Machine Reading Comprehension) collection of datasets includes 1 million real anonymized English questions from Microsoft Bing query logs together with a human generated answer and 9 million passages (Bajaj et al., 2016), that can be used both to test retrieval ranking and question answering.\n",
    "\n",
    "2. Build a search engine on that dataset using BM25\n",
    "3. Query the search engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c1cb0b-1a50-4b72-a1c2-95e195adf469",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyserini.search.lucene import LuceneSearcher\n",
    "\n",
    "# This loads a pre-built \"index\", which is a corpus modified to be more easily searchable.\n",
    "# It also loads a searcher based on modified tf-idf representations of documents (using the BM25 algorithm)\n",
    "lucene_bm25_searcher = LuceneSearcher.from_prebuilt_index('msmarco-v1-passage-full')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee4ac66-28f7-4371-81b5-09d2381fc9d5",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">Fill in the `query` variable before running the following cell of code:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676762fb-ff15-4a47-8cc2-94dafa88e7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '' # FILL IN your own query here or uncomment the example one below\n",
    "# query = 'what is a lobster roll?'\n",
    "\n",
    "hits = lucene_bm25_searcher.search(query)\n",
    "\n",
    "for i in range(0, 10):\n",
    "    print(f'{i+1:2} score {hits[i].score:.5f} {hits[i].lucene_document.get(\"raw\"):.{400}}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954ac842-f80d-4e1d-be9a-24bc1f51dcb2",
   "metadata": {},
   "source": [
    "FILL IN any observations from trying different queries here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d4f2d9-6630-4613-8c34-a5b52bbcfe8f",
   "metadata": {},
   "source": [
    "## View document vectors\n",
    "\n",
    "Now choose one of the documents that was surfaced with the prior query. Let's take a look at its raw term frequency vector and BM25-transformed vector.\n",
    "\n",
    "<span style=\"color:red\">Fill in the document's \"id\" as the `doc_id` variable in the next cell:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee44870-a235-4fd2-802b-cf00b9a4eae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyserini.index.lucene import LuceneIndexReader\n",
    "\n",
    "index_reader = LuceneIndexReader.from_prebuilt_index('msmarco-v1-passage-full')\n",
    "\n",
    "doc_id = ''\n",
    "tf = index_reader.get_document_vector(doc_id)\n",
    "print('******* Raw term frequency vector *******')\n",
    "print(sorted(tf.items(), key=lambda x: x[0]))\n",
    "print()\n",
    "\n",
    "bm25_vector = {term: index_reader.compute_bm25_term_weight(doc_id, term, analyzer=None) for term in tf.keys()}\n",
    "print('******* BM25 term frequency vector *******')\n",
    "print(sorted(bm25_vector.items(), key=lambda x: x[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a7e2b2-b15e-451d-b53e-a1fb656d0d38",
   "metadata": {},
   "source": [
    "**What kinds of words are weighted more highly in BM25?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079cb596-5ace-4556-9a65-68b23d627e7e",
   "metadata": {},
   "source": [
    "# Evaluate your model\n",
    "\n",
    "For ranked answers in a search engine, one metric is **mean reciprocal rank (MRR)**. For every test set instance, the system gets a score equivalent to the reciprocal of the rank of the first correct answer. So that would be 1/4 if the highest-ranked correct answer is 4. Overall for a test set $Q$,\n",
    "\n",
    "$$ MRR = \\frac{1}{|Q|} \\sum^{|Q|}_{i=1} \\frac{1}{rank_i}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb360b1-6c67-404c-a8ed-c462650160d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load example queries (\"topics\")\n",
    "from pyserini.search import get_topics\n",
    "\n",
    "topics = get_topics('msmarco-passage-dev-subset')\n",
    "print(f'{len(topics)} queries total')\n",
    "topics[1102400]['title'] # An example query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8ed56e-00b2-4ac4-8fae-086d351243d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all test queries on MS MARCO corpus with your BM25 system\n",
    "# Takes 1-5 minutes\n",
    "\n",
    "from pyserini.search.lucene import LuceneSearcher\n",
    "from tqdm import tqdm\n",
    "\n",
    "def run_all_queries(file, topics, searcher):\n",
    "    with open(file, 'w') as runfile:\n",
    "        cnt = 0\n",
    "        print('Running {} queries in total'.format(len(topics)))\n",
    "        for id in tqdm(topics):\n",
    "            query = topics[id]['title']\n",
    "            hits = searcher.search(query, 100) # only return the top 100 results\n",
    "            for i in range(0, len(hits)):\n",
    "                _ = runfile.write(f'{id}\\t{hits[i].docid}\\t{i+1}\\n') # from https://github.com/castorini/pyserini/blob/master/pyserini/output_writer.py\n",
    "\n",
    "lucene_bm25_searcher = LuceneSearcher.from_prebuilt_index('msmarco-v1-passage')\n",
    "\n",
    "run_all_queries('run-msmarco-passage-bm25.txt', topics, lucene_bm25_searcher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9018fae4-515c-418f-be21-ff6f2c19528f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyserini import search\n",
    "\n",
    "qrels_path = search.get_qrels_file('msmarco-passage-dev-subset')\n",
    "qrels_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f77865-dcb3-47a2-978a-de41daa83453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run evaluation to calculate mean reciprocal rank (MRR)\n",
    "! python -m pyserini.eval.msmarco_passage_eval \\\n",
    "   {qrels_path} \\\n",
    "   run-msmarco-passage-bm25.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d795a83b-4a47-4fba-8caa-7aa8d555c8c8",
   "metadata": {},
   "source": [
    "# (Optional) Try loading and processing your own corpus\n",
    "\n",
    "**First explore the session24_rag.ipynb notebook before doing this.**\n",
    "\n",
    "Possibilities:\n",
    "* [This class's textbook as PDF](https://web.stanford.edu/~jurafsky/slp3/ed3bookaug20_2024.pdf)\n",
    "* ACL Anthology of NLP papers: [full-text](https://huggingface.co/datasets/WINGNUS/ACL-OCL) or [BibTeX with abstracts](https://aclanthology.org/anthology+abstracts.bib.gz)\n",
    "* Enron email corpus: [tar.gz](https://www.cs.cmu.edu/~enron/enron_mail_20150507.tar.gz) or [Kaggle download](https://www.kaggle.com/datasets/wcukierski/enron-email-dataset)\n",
    "* Another website or blog of your choosing!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
