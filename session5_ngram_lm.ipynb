{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb050395-ffdb-43da-8788-59dfda9ba576",
   "metadata": {},
   "source": [
    "# N-gram language modeling\n",
    "Let's train an n-gram language model.\n",
    "\n",
    "Learning objectives for this notebook:\n",
    "* Train n-gram language models with smoothing to handle unseen n-grams\n",
    "* Compare generated text from n-gram language models trained on different sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8505c0e-b350-41a4-806d-5af436c79d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import sklearn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fb0ee96c-82c3-49fa-8fa0-fb2608eb6b18",
   "metadata": {},
   "source": [
    "## Load news text from Reuters\n",
    "Reuters from the '90s. Old news."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc10d990-f746-4558-88fe-e762ef506d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only need to run this once on your CRCD account\n",
    "import nltk\n",
    "nltk.download('reuters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8185eca-6a13-403b-b60a-1cd1b5306e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import reuters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee144528-fb29-406d-a3e4-41bbaab12dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = reuters.sents() # Load all sentences in the corpus and lowercase\n",
    "sents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee940156-1956-40a6-8831-daa256cbc4bb",
   "metadata": {},
   "source": [
    "# Preprocess the text into ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd233cd2-6327-4948-a298-c22ea3f6441f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase the data\n",
    "sents = [[word.lower() for word in doc] for doc in sents]\n",
    "sents[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab56504-4229-4c7a-8408-e0d37a47bfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly split into training and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random_seed =  # FILL IN an integer\n",
    "train, test = train_test_split(sents, test_size=0.1, random_state=random_seed)\n",
    "print(len(train))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff72574-5dbb-4928-ab9d-2bd4b0187c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "\n",
    "n = 2 # what order of ngram\n",
    "processed_train, vocab = padded_everygram_pipeline(n, train) \n",
    "# unfortunately can't inspect this as its a generator that's evaluated (\"filled in\") lazily"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4092ef4d-e837-481d-abae-1449eaca4394",
   "metadata": {},
   "source": [
    "# Train an n-gram language model with Lidstone smoothing\n",
    "To handle `<UNK>` (unseen) words, we will add a small pseudocount of 0.001, which is called \"Lidstone\" smoothing as the pseudocount $\\gamma$ is $0 < \\gamma < 1$. At $\\gamma = 1$, this is the same as Laplace smoothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52c33b2-e962-4931-8aea-8e730b4b361b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.lm import Lidstone\n",
    "\n",
    "# Initiate and fit an ngram language model\n",
    "lm = Lidstone(gamma=0.001, order=n)\n",
    "lm.fit(processed_train, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a6cc12-8791-409f-982c-57b50eb4ceaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL IN a random word to check its counts\n",
    "example_word = ''\n",
    "lm.counts[example_word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff851b8d-c8fe-4d1e-bfa4-c2cdb4b5429e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL IN an example bigram\n",
    "bigram_first_word = ''\n",
    "bigram_second_word = ''\n",
    "\n",
    "lm.counts[[bigram_first_word]][bigram_second_word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c619013-a6f8-4366-a5a6-5fe5b3c9c3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out the calculated probabilities for unigrams and bigrams (\"scores\")\n",
    "# These are the weights/parameters of the model, estimated from data\n",
    "\n",
    "print(lm.score(example_word))\n",
    "print(lm.score(bigram_second_word, [bigram_first_word]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688ba754-dbd6-40e6-a437-0669a5765f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out the log probabilities, which are used in practice. Why are they always negative?\n",
    "\n",
    "lm.logscore(example_word)"
   ]
  },
  {
   "attachments": {
    "d7bc3a95-804a-4e63-b144-0475824b0559.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "a0761492-9513-4455-a94f-dd7eac8ad603",
   "metadata": {},
   "source": [
    "![Log_(2).svg-1.png](attachment:d7bc3a95-804a-4e63-b144-0475824b0559.png)  \n",
    "A reminder of the natural log function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a1247b-3d4c-4291-8ece-bb5a6ad21832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test how it handles unseen words\n",
    "weird_word = '' # FILL IN a rare word that likely does not occur in '90s news\n",
    "print(lm.vocab.lookup(weird_word)) # How is it treating that word?\n",
    "print(lm.score(weird_word)) # What probability is it giving that word in the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7632b1-fe86-44b0-82a7-b37873a08caa",
   "metadata": {},
   "source": [
    "# Evaluate perplexity on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb39fb0b-7a78-4bb7-9658-ca9b094253ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test set into the same input format as the training set\n",
    "\n",
    "processed_test_generator, vocab = padded_everygram_pipeline(n, test) \n",
    "processed_test = [list(el) for el in list(processed_test_generator)]\n",
    "len(processed_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3582a840-0db5-40b4-9668-f9e991dba6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.perplexity(processed_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34941971-a583-4388-91cb-14ab6fa43098",
   "metadata": {},
   "source": [
    "# Sample (generate) from this trained language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c88da6-406e-42a6-8067-f81b5f0715f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell as many times as you like to take new samples (generate new phrases)\n",
    "# Record or copy the cell if there are any good ones you want to save and report back to the clas\n",
    "\n",
    "num_tokens = # FILL IN with how many tokens you want to generate\n",
    "prompt = [] # FILL IN with a list of tokens as a prompt (prior context). Or pass an empty list to just start generating\n",
    "generated_toks = lm.generate(num_words=num_tokens, text_seed=prompt)\n",
    "' '.join(prompt + generated_toks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42ae0a8-5ecd-4514-be12-8a9106123071",
   "metadata": {},
   "source": [
    "# Train an n-gram language model from a different data source\n",
    "Alright, let's train an n-gram language model from different data sources. You can choose from the following options, or try loading some other text data if you want!\n",
    "* Airbnb descriptions\n",
    "* Shakespeare plays\n",
    "\n",
    "Whichever you choose, you can skip to the corresponding part of the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6a4e31-10bf-40ce-9624-0b5e9503f6f6",
   "metadata": {},
   "source": [
    "## Airbnb descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f845149a-c5d2-4c36-b18a-a15d405827de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "import pandas as pd\n",
    "\n",
    "airbnb_filepath = '' # FILL IN the filepath to the CSV file with the Airbnb listings you should have somewhere still from session 2\n",
    "# If you don't have any Airbnb data, open and run session2_preprocessing.ipynb for instructions\n",
    "listings = pd.read_csv(airbnb_filepath) # reads CSV file into a pandas dataframe\n",
    "len(listings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3df3d20-5629-4a5b-a93a-a8bc113b8f06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Preprocess description column\n",
    "from nltk import word_tokenize\n",
    "from tqdm.auto import tqdm # for progress bar\n",
    "tqdm.pandas()\n",
    "\n",
    "def preprocess_airbnb(text):\n",
    "    stray_html = '<br />'\n",
    "    processed = text.replace(stray_html, ' ').lower()\n",
    "    return word_tokenize(processed)\n",
    "\n",
    "processed_airbnb = listings.description.dropna().progress_map(preprocess_airbnb).tolist()\n",
    "processed_airbnb[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c2a5da-1510-438c-a977-753aefd68c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare input for NLTK\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "\n",
    "n =  # FILL IN what order of ngram\n",
    "listings_input, vocab = padded_everygram_pipeline(n, processed_airbnb) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3704ce3e-bfea-491a-98cb-30f00ea87c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train n-gram language model\n",
    "from nltk.lm import Lidstone\n",
    "\n",
    "# Initiate and fit an ngram language model\n",
    "lm = Lidstone(gamma=0.001, order=n) # You can also play around with change the gamma value\n",
    "lm.fit(listings_input, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b62952-3aba-4956-acee-7071397db2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell as many times as you like to take new samples (generate new phrases)\n",
    "# Record or copy the cell if there are any good ones you want to save and report back to the clas\n",
    "\n",
    "num_tokens =  # FILL IN with how many tokens you want to generate\n",
    "prompt = [] # FILL IN with a list of tokens as a prompt (prior context). Or pass an empty list to just start generating\n",
    "generated_toks = lm.generate(num_words=num_tokens, text_seed=prompt)\n",
    "' '.join(prompt + generated_toks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355661a7-c77a-4b17-96a8-a534af1bca89",
   "metadata": {},
   "source": [
    "## Shakespeare plays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb380005-c72d-4bad-b051-71cf4d3826c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Shakespeare plays\n",
    "\n",
    "shakespeare = pd.read_csv('data/shakespeare_plays.csv', delimiter=';', header=None, names=['line_id', 'play', 'something', 'something_else', 'character', 'text'])\n",
    "shakespeare.info()\n",
    "shakespeare.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7bd064-af2b-4db9-99f4-599b9e6112b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess Shakespeare play lines\n",
    "from nltk import word_tokenize\n",
    "from tqdm.auto import tqdm # for progress bar\n",
    "tqdm.pandas()\n",
    "\n",
    "def preprocess_shakespeare(text):\n",
    "    processed = text.lower()\n",
    "    return word_tokenize(processed)\n",
    "\n",
    "processed = shakespeare.text.dropna().progress_map(preprocess_shakespeare).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65648f38-edb9-4c9c-84fe-87b149806bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "\n",
    "n =  # FILL IN what order of ngram\n",
    "shakespeare_input, vocab = padded_everygram_pipeline(n, processed) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d4adf6-8a6b-446c-925a-ae613fd66739",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.lm import Lidstone\n",
    "\n",
    "# Initiate and fit an ngram language model\n",
    "lm = Lidstone(gamma=0.001, order=n)\n",
    "lm.fit(shakespeare_input, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f8471a-0482-4955-b306-3f97de4d390b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell as many times as you like to take new samples (generate new phrases)\n",
    "# Record or copy the cell if there are any good ones you want to save and report back to the clas\n",
    "\n",
    "num_tokens = # FILL IN with how many tokens you want to generate\n",
    "prompt =  # FILL IN with a list of tokens as a prompt (prior context). Or pass an empty list to just start generating\n",
    "generated_toks = lm.generate(num_words=num_tokens, text_seed=prompt)\n",
    "' '.join(prompt + generated_toks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
