{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3dc1cc6-10e3-43e0-9b2a-9c3ab64ca08d",
   "metadata": {},
   "source": [
    "# Clickbait classification with neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a185e0-6f78-499d-9acb-baf6a9b1a28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the spacy English model without stuff we don't need\n",
    "nlp = spacy.load('en_core_web_sm', disable=['tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc00fe5-945f-4d1a-8089-8fbd3e945426",
   "metadata": {},
   "source": [
    "## Load clickbait data from Kaggle\n",
    "This data consists of headlines classified as clickbait or not (regular news). Source site: https://www.kaggle.com/datasets/amananandrai/clickbait-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90300de0-f52f-4122-a9bf-551271e1ff83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the dataset with pandas\n",
    "# 0 corresponds to not clickbait, 1 has been judged as clickbait\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Set pandas to display entire texts in dataframes\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "data = pd.read_csv('data/clickbait_data.csv')\n",
    "data.info()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e8cc3e-5f01-448c-ad24-4522945d4f8a",
   "metadata": {},
   "source": [
    "## Split into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0adbeff-1ebf-47b4-a88a-3711794e9681",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "test_size = int(0.1 * len(data))\n",
    "train, test  = train_test_split(data, test_size=test_size, random_state=9)\n",
    "print(len(train))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d809d550-dfb8-4182-b288-ae65e56de1d6",
   "metadata": {},
   "source": [
    "## Extract vector representations (embeddings) for documents\n",
    "This is different from usual! No sparse n-gram features here since they are so long and don't work as well with neural networks.\n",
    "\n",
    "Instead, we're calculating document embeddings as average word2vec embeddings from `spacy`. This provides a fixed-size vector representation for each headline that is not sparse (has a lot of 0s) but **dense** instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3167d7-24a7-47ec-9b14-dde4681a9e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_vecs = np.array([doc.vector for doc in nlp.pipe(train['headline'])])\n",
    "test_vecs = np.array([doc.vector for doc in nlp.pipe(test['headline'])])\n",
    "print(train_vecs.shape)\n",
    "print(test_vecs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30f79a2-8b03-4557-90cc-b6a19e304fc8",
   "metadata": {},
   "source": [
    "**How long are the document vectors here?** I.e. how many columns? Let's take a look at an example one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a07820-6260-4333-a578-f8036f94d939",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = # FILL IN a random number\n",
    "train_vecs[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d03e681-2b27-456e-b6e6-d4478944b063",
   "metadata": {},
   "source": [
    "## Train and evaluate a neural network for clickbait classification\n",
    "We'll use `scikit-learn`'s `MLPClassifier` class to train a classifier on these document vector thingies instead of hand-crafted features. This classifier provides an implementation of a feedforward neural network.\n",
    "\n",
    "Feel free to change the number of units and number of layers in the next cell and run it multiple times.  \n",
    "Here are some example values:\n",
    "\n",
    "* `(50,)` # 50 neurons in 1 hidden layer\n",
    "* `(30, 10)` # 30 neurons in the first hidden layer, then 10 in the second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b82b845-2adc-4606-8736-b68f3f60c3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "hidden_layers =  # FILL IN a tuple indicating how many units (neurons) are in each hidden layer (see text above)\n",
    "clf = MLPClassifier(hidden_layer_sizes=hidden_layers, max_iter=1000)\n",
    "train_x = train_vecs\n",
    "train_y = # FILL IN the reference to the pandas dataframe with the training set labels you are trying to predict\n",
    "clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dec200-f35c-42a5-bfff-c04591f35b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate FFNN classifier\n",
    "from sklearn.metrics import classification_report # this provides a bunch of useful evaluation metrics\n",
    "\n",
    "test_labels = test['clickbait'] # true (gold) test set labels for clickbait/not clickbait\n",
    "test_predictions = clf.predict(test_vecs)\n",
    "\n",
    "results = pd.DataFrame(classification_report(test_labels, test_predictions, output_dict=True))\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
