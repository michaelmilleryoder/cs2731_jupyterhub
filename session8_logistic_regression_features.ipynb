{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3dc1cc6-10e3-43e0-9b2a-9c3ab64ca08d",
   "metadata": {},
   "source": [
    "# Clickbait classification with logistic regression and custom features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc00fe5-945f-4d1a-8089-8fbd3e945426",
   "metadata": {},
   "source": [
    "## Load clickbait data from Kaggle\n",
    "This data consists of headlines classified as clickbait or not (regular news). Source site: https://www.kaggle.com/datasets/amananandrai/clickbait-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90300de0-f52f-4122-a9bf-551271e1ff83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the dataset with pandas\n",
    "# 0 corresponds to not clickbait, 1 has been judged as clickbait\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Set pandas to display entire texts in dataframes\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "data = pd.read_csv('data/clickbait_data.csv')\n",
    "data.info()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e8cc3e-5f01-448c-ad24-4522945d4f8a",
   "metadata": {},
   "source": [
    "## Split into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0adbeff-1ebf-47b4-a88a-3711794e9681",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "test_size = int(0.1 * len(data))\n",
    "train, test  = train_test_split(data, test_size=test_size, random_state=9)\n",
    "print(len(train))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d809d550-dfb8-4182-b288-ae65e56de1d6",
   "metadata": {},
   "source": [
    "## Extract unigram (raw bag-of-word count) features from the text data\n",
    "As a reminder, this step converts each headline to a numeric vector of unigram counts (how many times each word type occurs).\n",
    "\"Training\" the vectorizer means finding how many unique features (in this case, unique words) are in the training set. This sets the number of columns in the matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f76f8e-26ca-48b4-9a76-21f728f99a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "\n",
    "unigram_vectorizer = CountVectorizer(tokenizer=nltk.word_tokenize)\n",
    "unigram_vectorizer.fit(train['headline']) # input is a list of strings (documents)\n",
    "train_features = unigram_vectorizer.transform(train['headline'])\n",
    "test_features = unigram_vectorizer.transform(test['headline'])\n",
    "\n",
    "print(type(train_features))\n",
    "print(train_features.shape) # prints (number of rows in the matrix, number of columns)\n",
    "print(test_features.shape)  # prints (number of rows in the matrix, number of columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30f79a2-8b03-4557-90cc-b6a19e304fc8",
   "metadata": {},
   "source": [
    "Now let's add a custom feature of our own design. Specifically, let's add the number of words. Who knows, maybe clickbait is often longer or shorter than real news headlines? First we'll calculate that feature as a vector of lengths, one for each document (headline)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e1b97f-9507-4e14-919c-dbfa3d591ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['tokenized_headline'] = train['headline'].map(nltk.word_tokenize) # tokenization\n",
    "train['num_words'] = train['tokenized_headline'].str.len()\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabe9f3a-9d26-4f4d-80d6-4456a1cf4168",
   "metadata": {},
   "source": [
    "Let's plot the distribution of the number of words (length) across clickbait and non-clickbait using the `seaborn` package. If there seems to be a difference in lengths between clickbait and non-clickbait, this could be a useful feature for our model to learn to distinguish them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aad88a8-d9fc-43f2-bcff-e6cbe482a4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the distribution of lengths across clickbait and non-clickbait\n",
    "import seaborn as sns\n",
    "\n",
    "sns.catplot(data=train, x='clickbait', y='num_words', kind='box')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c86200-7aba-4166-a818-df5d11d7cce8",
   "metadata": {},
   "source": [
    "**Does there seem to be a difference in the number of words between clickbait and non-clickbait headlines?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bc9fce-5d28-47fc-b684-4a591a063e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['tokenized_headline'] = test['headline'].map(nltk.word_tokenize) # tokenization\n",
    "test['num_words'] = test['tokenized_headline'].str.len()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8858e6f-3d38-49f5-966a-69f5d84c20b1",
   "metadata": {},
   "source": [
    "You can use the `scipy.sparse.hstack` function to combine the n-gram features (which are a `scipy` sparse matrices) with a the column of word lengths. In this way you are horizontally \"stacking\" new columns onto the matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb33dda6-a893-4e27-968f-fdfce2e8becf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "\n",
    "custom_train_feature = np.expand_dims(train['num_words'], axis=1) # make the new column a 2-dimensional NumPy array for concatenating with ngram features\n",
    "custom_train_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa83910-9a79-4e8b-81cb-b1638f114bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_features.shape) # original shape\n",
    "custom_train_features = hstack([train_features, custom_train_feature])\n",
    "print(custom_train_features.shape) # new shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468ed359-3c1f-4d00-bcab-2ad4b16c8608",
   "metadata": {},
   "source": [
    "What is that new column in the training set features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbd6f50-a820-458c-b92e-8b6ec860c4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the feature to the test set, too\n",
    "\n",
    "custom_test_feature = np.expand_dims(test['num_words'], axis=1) # make the new column a 2-dimensional NumPy array for concatenating with ngram features\n",
    "\n",
    "print(test_features.shape) # original shape\n",
    "custom_test_features = hstack([test_features, custom_test_feature])\n",
    "print(custom_test_features.shape) # new shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d03e681-2b27-456e-b6e6-d4478944b063",
   "metadata": {},
   "source": [
    "## Train and evaluate a logistic regression model for clickbait classification\n",
    "We'll use `scikit-learn`'s `LogisticRegression` class to train 2 classifiers: one just using unigram features, and the other using unigram features **plus word lengths**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b82b845-2adc-4606-8736-b68f3f60c3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf_unigrams = LogisticRegression() # Instantiate a logistic regression classifier\n",
    "clf_unigrams.fit(train_features, train['clickbait']) # Train the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e82e59c-8708-4feb-ad6e-177c81a79d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_combined = LogisticRegression() # Instantiate a logistic regression classifier\n",
    "clf_combined.fit(custom_train_features, train['clickbait']) # Train the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dec200-f35c-42a5-bfff-c04591f35b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate unigram logistic regression classifier\n",
    "from sklearn.metrics import classification_report # this provides a bunch of useful evaluation metrics\n",
    "\n",
    "test_labels = test['clickbait'] # true (gold) test set labels for clickbait/not clickbait\n",
    "unigram_test_predictions = clf_unigrams.predict(test_features)\n",
    "\n",
    "results = pd.DataFrame(classification_report(test_labels, unigram_test_predictions, output_dict=True))\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac7e9d0-0a23-449c-9d2b-ee7cde0e3a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate unigram + custom features logistic regression classifier\n",
    "\n",
    "combined_test_predictions = clf_combined.predict(custom_test_features)\n",
    "results = pd.DataFrame(classification_report(test_labels, combined_test_predictions, output_dict=True))\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6ad469-c199-466c-8bfb-0d14fa5f73bd",
   "metadata": {},
   "source": [
    "**Do you see any improvement from adding our custom feature?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba29d9d7-9515-42de-a906-b1a38650e04d",
   "metadata": {},
   "source": [
    "# Find most informative features from logistic regression\n",
    "Logistic regression stores one model weight (parameter) per feature. We'll examine these learned feature weights to see which features are most strongly associated with each output class (clickbait and not clickbait)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5662ac7d-9025-4b2e-9f50-5263feffacc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This array is where the log probabilities of each feature for the positive class (clickbait) are stored\n",
    "clf_combined.coef_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128e3ac8-561c-4582-9e44-27784a1816df",
   "metadata": {},
   "source": [
    "**What does the number of columns in this matrix of coefficients (weights) correspond to?**  \n",
    "\n",
    "Let's now rank the weights and list the features that correspond to the highest and lowest weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4d21e4-a460-4e29-bed2-cf3bb1c5c0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = unigram_vectorizer.get_feature_names_out().tolist() + ['num_words']\n",
    "len(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994f50e9-9a28-4b66-979f-921e21040911",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fff1e3-71d8-47b1-baa0-909d8cb3473b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_informative_features(feature_names, classifier, class_id=1, n=10):\n",
    "    assert len(feature_names) == classifier.coef_.shape[1]\n",
    "    if class_id == 1: # positive class\n",
    "        topn = reversed(sorted(zip(classifier.coef_[0], feature_names))[-n:])\n",
    "    else: # negative class\n",
    "        topn = sorted(zip(classifier.coef_[0], feature_names))[:n]\n",
    "    for coef, feat in topn:\n",
    "        print(feat, coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21b3ee8-05df-4bac-af96-7271a747e685",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clf_combined # FILL IN the classifier you want to examine\n",
    "class_id = 1 # FILL in the class ID you want to examine\n",
    "most_informative_features(feature_names, clf, class_id=class_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb5d1ad-066d-4cba-95e7-ba37eee12c9c",
   "metadata": {},
   "source": [
    "Feel free to duplicate the above cell and check informative features for different classes and classifiers.\n",
    "\n",
    "Are any features surprising? Feel free to add more cells and try to investigate where some of these features occur in the training data. The pandas function `df.col.str.contains(string)` may be helpful for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2af808-d9e9-4dca-8f20-507552bcd464",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
