{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3dc1cc6-10e3-43e0-9b2a-9c3ab64ca08d",
   "metadata": {},
   "source": [
    "# N-gram document representations of headlines\n",
    "This notebook guides you through creating n-gram representations of headlines. We'll examine these representations and use them as features for a simple machine learning model to classify headlines as clickbait or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd1bb16-d13a-488c-800b-5f8fb4f58f27",
   "metadata": {},
   "source": [
    "## Import necessary packages\n",
    "These should be automatically available in the class conda environment. If this doesn't work, make sure you specified `/ix/cs2731_fall2025f/class_env` when launching JupyterHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6443dda-9967-4c06-8dc9-ef35e1c3c2a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas\n",
    "import nltk\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc00fe5-945f-4d1a-8089-8fbd3e945426",
   "metadata": {},
   "source": [
    "## Load clickbait data from Kaggle\n",
    "This data consists of headlines classified as clickbait or not (regular news). It is from a dataset on Kaggle, a site where machine learning competitions and datasets are often hosted. Source site: https://www.kaggle.com/datasets/amananandrai/clickbait-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90300de0-f52f-4122-a9bf-551271e1ff83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the dataset with pandas\n",
    "# 0 corresponds to not clickbait, 1 has been judged as clickbait\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Set pandas to display entire texts in dataframes\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "data = pd.read_csv('data/clickbait_data.csv')\n",
    "data.info()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e8cc3e-5f01-448c-ad24-4522945d4f8a",
   "metadata": {},
   "source": [
    "## Split into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0adbeff-1ebf-47b4-a88a-3711794e9681",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "test_size = int(0.1 * len(data))\n",
    "train, test  = train_test_split(data, test_size=test_size, random_state=9)\n",
    "print(len(train))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef27c093-060b-45f7-8137-b824d83c6ff7",
   "metadata": {},
   "source": [
    "**What does this \"length\" refer to?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d809d550-dfb8-4182-b288-ae65e56de1d6",
   "metadata": {},
   "source": [
    "## Extract **n-gram features** from the raw text data\n",
    "Features are data fields or attributes extracted from raw data, in our case, text data. The features were are examining here are \"unigram\" features, counts of the number of instances of each word type. This step converts each headline to a numeric vector of unigram counts (how many times each word type occurs).\n",
    "\"Training\" the vectorizer means finding how many unique features (in this case, word types) are in the training set. This sets the number of columns in the term-document matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f76f8e-26ca-48b4-9a76-21f728f99a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "\n",
    "unigram_vectorizer = CountVectorizer(tokenizer=nltk.word_tokenize)\n",
    "unigram_vectorizer.fit(train['headline']) # input is a list of strings (documents)\n",
    "train_unigram_features = unigram_vectorizer.transform(train['headline'])\n",
    "test_unigram_features = unigram_vectorizer.transform(test['headline'])\n",
    "\n",
    "print(type(train_unigram_features))\n",
    "print(train_unigram_features.shape) # prints (number of rows in the matrix, number of columns)\n",
    "print(test_unigram_features.shape)  # prints (number of rows in the matrix, number of columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30f79a2-8b03-4557-90cc-b6a19e304fc8",
   "metadata": {},
   "source": [
    "Let's explore those training set unigram features a bit more. First convert the `scipy` sparse matrix into a regular `numpy` matrix to take a look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab18ef8-1ce6-47d8-a1ac-2c8b19b16e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_features = train_unigram_features.toarray()\n",
    "print(type(unigram_features))\n",
    "print(unigram_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc38c76-77ef-4ee3-8e50-eb89176773b1",
   "metadata": {},
   "source": [
    "Each row in this matrix is a headline. Each column is the count of a unique word type. **How many words are there in the entire vocabulary of this dataset?**  \n",
    "Let's take a look at a few example headline vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171de09f-40b8-4408-92bf-7d9967fe45fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_index =  # FILL IN a random number less than the number of rows (datapoints) in ngram_features here\n",
    "train.iloc[sample_index] # Take a look at the text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d596dd72-5b05-4107-bc34-f084dcb82d8c",
   "metadata": {},
   "source": [
    "How many values in this large, sparse vector that represents this sample document aren't 0?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fc3e1b-1697-43a6-b02c-92b2491371f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.count_nonzero(unigram_features[sample_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ef672b-f8f6-4841-89d1-ce2389a28255",
   "metadata": {},
   "source": [
    "Label the nonzero features with the words they correspond to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2e833c-97ad-497a-9ecd-d9fd9a197d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a pandas dataframe from the ngram features and label the column with their corresponding feature (unigram or word type)\n",
    "feature_names = unigram_vectorizer.get_feature_names_out()\n",
    "print(len(feature_names))\n",
    "\n",
    "unigram_feature_matrix = pd.DataFrame(unigram_features, columns=feature_names)\n",
    "unigram_feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa1ef1c-b46f-4d04-ace7-3c51d1a4aa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the nonzero values in the feature vector for the example headline\n",
    "column_mask = unigram_feature_matrix.loc[sample_index].apply(lambda x: x > 0)\n",
    "nonzero_columns = column_mask[column_mask == True]\n",
    "unigram_feature_matrix.loc[[sample_index], nonzero_columns.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0011d359-3f82-465c-89e0-c49f00c2da85",
   "metadata": {},
   "source": [
    "## Extract bigram features\n",
    "Unigram features are counts of word types, which can also be viewed as unique sequences of just 1 word. Here we use **bigram** features, which are counts of unique sequences of 2 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5767732-e02c-4af4-bd25-043ba0b8d1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_vectorizer = CountVectorizer(ngram_range=(2,2), tokenizer=nltk.word_tokenize) # note the ngram_range parameter\n",
    "bigram_vectorizer.fit(train['headline'])\n",
    "train_bigram_features = bigram_vectorizer.transform(train['headline'])\n",
    "test_bigram_features = bigram_vectorizer.transform(test['headline'])\n",
    "\n",
    "print(train_bigram_features.shape) # prints (number of rows in the matrix, number of columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1708ba2d-ceb1-4c09-bfa8-68116e77f595",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_feature_matrix = pd.DataFrame(train_bigram_features.toarray(), columns=bigram_vectorizer.get_feature_names_out())\n",
    "bigram_feature_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9fd98d-dda7-4242-948d-c44a5f29f5b0",
   "metadata": {},
   "source": [
    "**How many bigram features do we have? Why is this so much bigger than the number of unigram features?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e302efcb-692b-4f55-bf2f-4cd332af6880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the nonzero values in the feature vector for the example headline\n",
    "column_mask = bigram_feature_matrix.loc[sample_index].apply(lambda x: x > 0)\n",
    "nonzero_columns = column_mask[column_mask == True]\n",
    "bigram_feature_matrix.loc[[sample_index], nonzero_columns.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6dcfd2c-ee22-4fee-884f-81489eebbc4e",
   "metadata": {},
   "source": [
    "# Cosine similarity\n",
    "We can use the numeric feature vectors computed for every headline to compute similarities with other headlines using **cosine similarity**. Though contemporary information retreival (search engine) systems are of course much more complex, they still use this basic framework to return results: convert texts to vectors and return the most similar documents to your query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f58f9a-ea3a-4868-8809-166db32ebdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cosine similarity between the sample headline vector and all other headlines in the training set\n",
    "\n",
    "from scipy.spatial.distance import cosine # cosine distance from the scipy package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d376b82-2990-4ea7-b05a-7325db3ca26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_vector = unigram_features[sample_index]\n",
    "sample_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77bf488-af1f-4d0d-b431-c83309a19d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cosine_similarity_to_sample(vector):\n",
    "    \"\"\" Compute cosine similarity with sample vector \"\"\"\n",
    "    return 1 - cosine(vector, sample_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fd726c-9606-4ec6-91da-e36430618fad",
   "metadata": {},
   "source": [
    "As a refresher, let's take a look at the shapes of these matrices and what the sample headline is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314de55f-041e-46fa-836d-e4bb8279647d",
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_feature_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d2c3cd-61c0-4d1d-8ce0-897aa3bf1790",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.iloc[sample_index] # Take a look at the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48849100-3486-47cd-bb85-ea4da7b74d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f35ef43-d5bf-492b-9f73-a35b863e3d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities = unigram_feature_matrix.apply(compute_cosine_similarity_to_sample, axis=1) # apply function over every row in the df\n",
    "similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f6ebc1-dfc2-4a8c-af28-954e4421eb19",
   "metadata": {},
   "source": [
    "A sanity check first. What should the sample vector's similarity with itself be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6a71c1-4d77-45b6-bf37-8b9323ea7c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities[sample_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54022db-5015-4473-9c76-12a581b24055",
   "metadata": {},
   "source": [
    "Now let's rank similarities and find out which vectors are most similar to the sample headline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e722227-6017-4981-b4ef-fa31d3a28ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_similarities = similarities.sort_values(ascending=False)\n",
    "sorted_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc5538d-e3cb-46cf-b9bf-98cc3d4fedde",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.iloc[sorted_similarities.index[:10]] # Take a look at the top 10 most similar headlines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ae3612-cfd3-4c0c-ad4c-89af2441c717",
   "metadata": {},
   "source": [
    "# Clickbait classification\n",
    "Now let's create a simple machine learning model to classify whether headlines are clickbait or not. We'll use the n-gram features we extracted as input!\n",
    "\n",
    "Do you n-gram features will be enough to classify clickbait? **What information is lost by representing documents as ngrams?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1253dd63-52d2-4642-ba9b-3c645a4c7acc",
   "metadata": {},
   "source": [
    "## Train Naive Bayes model\n",
    "Naive Bayes is a simple machine learning algorithm that we won't be covering in the course. But you know that as a machine learning model, it learns patterns (parameters in a mathematical model) from a training set.\n",
    "\n",
    "That trained model can then be used to make predictions.\n",
    "\n",
    "In our dataset, `train['clickbait']` is the column that contains the **output** we care about: whether the text is clickbait or not. We pass the example input and output in our training set to train the model.\n",
    "\n",
    "You can select whether to use unigram or bigram features. Try them both!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e3ea50-da4b-4787-af66-36de9aef5c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = MultinomialNB()\n",
    "train_features =  # FILL IN with the variable name of the training features to use (unigrams or bigrams)\n",
    "clf.fit(train_features, train['clickbait'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86c6080-8c63-4171-9478-556e9bd6d005",
   "metadata": {},
   "source": [
    "## Make predictions from the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e1b3af-27bb-4ec8-9fe2-03a2c0f07b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select an example from the test set\n",
    "# Note that the classifier has never seen this example\n",
    "\n",
    "example = test.sample(1)\n",
    "example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03afe0f-83b8-417b-b29a-bcd98a3e14f5",
   "metadata": {},
   "source": [
    "Get the text into a vector format that the classifier can use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653b598b-6653-400a-be79-40fe4846303e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer =  # FILL IN the variable name of the vectorizer to use (unigram or bigram)\n",
    "example_features = unigram_vectorizer.transform(example['headline'])\n",
    "example_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb13dc7-bdee-4f08-9789-5727e37e1315",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(example_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7256cbea-290c-45b6-8f12-b797543dade1",
   "metadata": {},
   "source": [
    "**Did the model correctly predict the unseen example?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73800c48-ec62-4930-ad45-f08a201792a3",
   "metadata": {},
   "source": [
    "## Evaluation on a test set\n",
    "Now let's quantitatively evaluate our model on the **test set**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745467b8-52c0-4a35-8457-b249aa55a92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "test_labels = test['clickbait'] # true (gold) test set labels for clickbait/not clickbait\n",
    "\n",
    "test_features =  # FILL IN with variable name of test features to use (unigrams or bigrams)\n",
    "test_predictions = clf.predict(test_features)\n",
    "\n",
    "np.mean(test_predictions == test_labels) # a quick measure of accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
